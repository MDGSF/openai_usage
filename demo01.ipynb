{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai api usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pip install -i https://pypi.tuna.tsinghua.edu.cn/simple openai`\n",
    "- `pip install -i https://pypi.tuna.tsinghua.edu.cn/simple python-dotenv`\n",
    "- `pip install -i https://pypi.tuna.tsinghua.edu.cn/simple redlines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.proxy = {\n",
    "    \"http\": \"http://192.168.60.1:1080\", \n",
    "    \"https\": \"http://192.168.60.1:1080\"\n",
    "}\n",
    "model='gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model='gpt-3.5-turbo', temperature=0):\n",
    "    messages = [{'role': \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model='gpt-3.5-turbo', temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles of Prompting\n",
    "\n",
    "- Principle 1: Write clear and specific instructions, clear != short.\n",
    "- Principle 2: Give the model time to think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 1: Use delimiters\n",
    "\n",
    "- Triple quotes: \"\"\"\n",
    "- Triple backticks: ```\n",
    "- Triple dashes: ---\n",
    "- Angle brackets: < >\n",
    "- XML tags: `<tag> </tag>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expiration of the pandemic-era policy in the US that allowed authorities to rapidly expel most asylum seekers under the pretext of public health has led to large numbers of migrants and refugees rushing to the US-Mexico border in hopes of seeking protection, while President Joe Biden's administration dispatched additional troops and resources to brace for an influx of arrivals.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Attention once again turned to the US-Mexico border this week as a pandemic-era policy in the United States that allowed authorities to rapidly expel most asylum seekers under the pretext of public health expired.\n",
    "\n",
    "Large numbers of migrants and refugees rushed to the border in hopes of seeking protection in the US in advance of the expiration of Title 42 late on Thursday, as new restrictions on asylum also came into effect.\n",
    "\n",
    "At the same time, President Joe Biden’s administration had dispatched additional troops and other resources as authorities braced for an influx of arrivals.\n",
    "\n",
    "Here are some of the stories that have marked the past few days along the 3,140km (1,950-mile) international border.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\\n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 2: Ask for structured output\n",
    "\n",
    "HTML or JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"book_id\": 1,\n",
      "    \"title\": \"The Lost City of Zorath\",\n",
      "    \"author\": \"Aria Blackwood\",\n",
      "    \"genre\": \"Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 2,\n",
      "    \"title\": \"The Last Survivors\",\n",
      "    \"author\": \"Ethan Stone\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 3,\n",
      "    \"title\": \"The Secret Life of Bees\",\n",
      "    \"author\": \"Lila Rose\",\n",
      "    \"genre\": \"Romance\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\\n",
    "with their authors and genres.\n",
    "Privide then in JSON format with the following keys:\n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 3: Check whether conditions are satisfied\n",
    "\n",
    "Check assumptions required to do the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 = Get some water boiling.\n",
      "Step 2 = Grab a cup and put a tea bag in it.\n",
      "Step 3 = Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 = Let it sit for a bit so the tea can steep.\n",
      "Step 5 = After a few minutes, take out the tea bag.\n",
      "Step 6 = If you like, add some sugar or milk to taste.\n",
      "Step 7 = Enjoy your delicious cup of tea!\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\\n",
    "water boiling. While that's happening, \\\n",
    "grab a cup and put a tea bag in it. Once the water is \\\n",
    "hot enough, just pour it over the tea bag. \\\n",
    "Let it sit for a bit so the tea can steep. After a \\\n",
    "few minutes, take out the tea bag. If you \\\n",
    "like, you can add some sugar or milk to taste. \\\n",
    "and that's it! you've got yourself a delicious \\\n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes.\n",
    "If it contains a sequences of instructions, \\\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 = ...\n",
    "Step 2 = ...\n",
    "...\n",
    "Step N = ...\n",
    "\n",
    "If the text does not contain a sequences of instructions, \\\n",
    "then simply write \\\"No steps privided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 4: Few-shot prompting\n",
    "\n",
    "Give successful examples of completing tasks.\n",
    "Then ask model to perform the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Resilience is like a tree that bends with the wind but never breaks. It is the ability to bounce back from adversity and keep moving forward, even when things get tough. Just like a tree, we must have strong roots and a solid foundation to weather any storm that comes our way.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\\n",
    "valley flows from a modest spring: the \\\n",
    "grandest symphony originates from a single note; \\\n",
    "the nost intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle 2\n",
    "\n",
    "Give the model time to think\n",
    "\n",
    "### Tactic 1: Specify the steps to complete a task\n",
    "\n",
    "```text\n",
    "Step 1: ...\n",
    "Step 2: ...\n",
    "...\n",
    "Step N: ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Two siblings, Jack and Jill, go on a quest to fetch water from a well on a hill, but misfortune strikes when Jack trips and tumbles down the hill, with Jill following suit, yet they return home slightly battered but with their adventurous spirits still intact.\n",
      "\n",
      "Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits sur une colline, mais la malchance frappe quand Jack trébuche et dégringole la colline, avec Jill qui suit, mais ils rentrent chez eux légèrement meurtris mais avec leurs esprits aventureux toujours intacts. \n",
      "\n",
      "Jack, Jill. \n",
      "\n",
      "{\n",
      "  \"french_summary\": \"Deux frères et sœurs, Jack et Jill, partent en quête d'eau d'un puits sur une colline, mais la malchance frappe quand Jack trébuche et dégringole la colline, avec Jill qui suit, mais ils rentrent chez eux légèrement meurtris mais avec leurs esprits aventureux toujours intacts.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\\n",
    "a quest to fetch water from a hilltop \\\n",
    "well. As they climbed, singing joyfully, misfortune \\\n",
    "struck-Jack tripped on a stone and tumbled \\\n",
    "down the hill, with Jill following suit. \\\n",
    "Though slightly battered, the pair returned home to \\\n",
    "comforting embraces. Despite the nishap, \\\n",
    "their adventurous spirits remained undinned, and they \\\n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Perform the following actions:\n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (\"Completion for prompt 1:\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 2:\n",
      "Summary: Jack and Jill go on a quest to fetch water, but misfortune strikes and they tumble down a hill before returning home with their adventurous spirits still intact.\n",
      "Translation: Jack et Jill partent en quête d'eau, mais un malheur frappe et ils tombent d'une colline avant de rentrer chez eux avec leurs esprits aventureux toujours intacts.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"french_summary\": \"Jack et Jill partent en quête d'eau, mais un malheur frappe et ils tombent d'une colline avant de rentrer chez eux avec leurs esprits aventureux toujours intacts.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\\n",
    "a quest to fetch water from a hilltop \\\n",
    "well. As they climbed, singing joyfully, misfortune \\\n",
    "struck-Jack tripped on a stone and tumbled \\\n",
    "down the hill, with Jill following suit. \\\n",
    "Though slightly battered, the pair returned home to \\\n",
    "comforting embraces. Despite the nishap, \\\n",
    "their adventurous spirits remained undinned, and they \\\n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = f\"\"\"\n",
    "Your task is to perform the following actions:\n",
    "1 - Summarize the following text delimited by\n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following\n",
    "  keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in Italian summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text to summarize: <{text}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt2)\n",
    "print (\"Completion for prompt 2:\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    "help working out the financials.\n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations\n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,00 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "Is the student's solution the same as the actual solution just calculated:\n",
      "No\n",
      "\n",
      "student grade:\n",
      "Incorrect\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem.\n",
    "- Then compare your solution to the student's solution \\\n",
    "and evaluate if the student's solution is correct or not.\n",
    "Don't decide if the student's solution is correct until\n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as the actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need \\\n",
    "help working out the financials.\n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations\n",
    "as a function of the number of square feet.\n",
    "```\n",
    "Student's Solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,00 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Limitations\n",
    "\n",
    "- Hallucination\n",
    "- Makes statements that sound plausible but are not true\n",
    "- Reducing hallucinations:\n",
    "- First find relevant information,\n",
    "- then answer the question\n",
    "- based on the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush that uses advanced sonic technology to provide a deep and thorough clean. It features a slim and sleek design that makes it easy to hold and maneuver, and it comes with a range of smart features that help you optimize your brushing routine.\n",
      "\n",
      "One of the key features of the AeroGlide UltraSlim Smart Toothbrush is its advanced sonic technology, which uses high-frequency vibrations to break up plaque and bacteria on your teeth and gums. This technology is highly effective at removing even the toughest stains and buildup, leaving your teeth feeling clean and refreshed.\n",
      "\n",
      "In addition to its sonic technology, the AeroGlide UltraSlim Smart Toothbrush also comes with a range of smart features that help you optimize your brushing routine. These include a built-in timer that ensures you brush for the recommended two minutes, as well as a pressure sensor that alerts you if you're brushing too hard.\n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush by Boie is a highly advanced and effective toothbrush that is perfect for anyone looking to take their oral hygiene to the next level. With its advanced sonic technology and smart features, it provides a deep and thorough clean that leaves your teeth feeling fresh and healthy.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Prompt Development\n",
    "\n",
    "Prompt guidelines:\n",
    "\n",
    "- Be clear and specific\n",
    "- Analyze why result does not give desired output.\n",
    "- Refine the idea and the prompt\n",
    "- Repeat\n",
    "\n",
    "Iterative Process:\n",
    "\n",
    "- Try something\n",
    "- Analyze where the result does not give what your want\n",
    "- Clarify instructions, give more time to think\n",
    "- Refine prompts with a batch of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "\n",
    "总结文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft and cute panda plush toy loved by daughter, but a bit small for the price. Arrived early.\n"
     ]
    }
   ],
   "source": [
    "Prod_review = f\"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\\n",
    "super cute, and its face has a frendly look. It's \\\n",
    "a bit samll for what I paid though. I think there \\\n",
    "might be other options that are bigger for the \\\n",
    "same price. It arrived a day earlier than expected, \\\n",
    "so I got to play with it myself before I gave it \\\n",
    "to her.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words.\n",
    "\n",
    "Review: ```{Prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The panda plush toy arrived a day earlier than expected, but the customer felt it was a bit small for the price paid.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "Shipping department.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects\n",
    "that mention shipping and delivery of the product.\n",
    "\n",
    "Review: ```{Prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```Soft and cute panda plush toy, loved by daughter. Friendly face. Small for the price, other options may offer better value. Arrived early.```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "pricing department, responsible for determining the \\\n",
    "price of the product.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects\n",
    "that are relevant to the price and perceived value.\n",
    "\n",
    "Review: ```{Prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The product arrived a day earlier than expected.\" (11 words)\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\\n",
    "a product review from an ecommerce site to give \\\n",
    "feedback to the Shipping department.\n",
    "\n",
    "From the review below, delimited by triple quotes\n",
    "extract the information relevant to shipping and \\\n",
    "delivery. Limit to 30 words.\n",
    "\n",
    "Review: ```{Prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring\n",
    "\n",
    "推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例一：判断是积极情绪还是消极情绪**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast. The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together. I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "Which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例二：提取情绪**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satisfied, grateful, impressed, content, pleased\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例三：判断是否生气**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger? \\\n",
    "The reivew is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例四：提取商品和品牌**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例五：同时提取多个信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": false,\n",
      "  \"Item\": \"lamp with additional storage\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例六：提取主题词语**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government survey, job satisfaction, NASA, Social Security Administration, employee concerns\n",
      "['government survey', ' job satisfaction', ' NASA', ' Social Security Administration', ' employee concerns']\n"
     ]
    }
   ],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the goverment,\n",
    "public sector employees were asked to rate their level\n",
    "of satisfaction with the department they work at.\n",
    "The results revealed that NASA was the most popular\n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings,\n",
    "stating, \"I'm not surprised that NASA came out on top.\n",
    "It's a great place to work with amazing people and\n",
    "incredible opportunities. I'm proud to be a part of\n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team,\n",
    "with Director Tom Johnson stating, \"We are thrilled to\n",
    "hear that our employees are satisfied with their work at NASA.\n",
    "Web have a talented and dedicated team who work tirelessly\n",
    "to achieve our goals, and it's fantastic to see that their\n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the\n",
    "Social Security Administration had the lowest satisfaction\n",
    "rating, with only 45% of employees indicating they were\n",
    "satisfied with their job. The government has pledged to\n",
    "address the concerns raised by employees in the survey and\n",
    "work towards improving job satisfaction across all department.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long.\n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)\n",
    "print (response.split(sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例七：判断文章和给定主题是否相关**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa: 1\n",
      "local government: 0\n",
      "engineering: 0\n",
      "employee satisfaction: 1\n",
      "federal government: 1\n"
     ]
    }
   ],
   "source": [
    "topic_list = [\n",
    "    \"nasa\", \"local government\", \"engineering\",\n",
    "    \"employee satisfaction\", \"federal government\"\n",
    "]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic. \\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming\n",
    "\n",
    "Translating to a different language, and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例一：一种语言翻译为另一种语言**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, me gustaría ordenar una licuadora.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\\n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例二：判断给定文本是什么语言**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Spanish.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me which language this is:\n",
    "```Hola, me gustaría ordenar una licuadora.```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例三：一种语言翻译为其它多种语言**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese: 我想订购一个篮球 (Wǒ xiǎng dìnggòu yīgè lánqiú)\n",
      "French: Je veux commander un ballon de basket (Jeuh vuh koh-mahn-deh uhn bah-lawn duh bah-sket)\n",
      "Spanish: Quiero ordenar una pelota de baloncesto (Kee-eh-roh or-deh-nahr oo-nah peh-loh-tah deh bah-lon-ces-toh)\n",
      "English: I want to order a basketball\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following text to Chinese, French, Spanish and English: \\\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例四：翻译为正式和非正式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal: ¿Le gustaría ordenar una almohada?\n",
      "Informal: ¿Te gustaría ordenar una almohada?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish in both the \\\n",
    "formal and informal forms:\n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例五：翻译**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message (The language is English.): My screen is flickering.\n",
      "English: My screen is flickering.\n",
      "Korean: 화면이 깜빡입니다.\n",
      "Original message (This is Spanish.): Mi pantalla está parpadeando.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-pl00j8lMTfSiSVEB4xATsheQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal message (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00missue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mTranslate the following text to English \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mand Korean: ```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00missue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m (response)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-pl00j8lMTfSiSVEB4xATsheQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "user_messages = [\n",
    "  \"My screen is flickering.\",\n",
    "  \"Mi pantalla está parpadeando.\",\n",
    "  \"我的屏幕在闪烁\"\n",
    "]\n",
    "\n",
    "for issue in user_messages:\n",
    "  prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "  lang = get_completion(prompt)\n",
    "  print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "  prompt = f\"\"\"\n",
    "  Translate the following text to English \\\n",
    "  and Korean: ```{issue}```\n",
    "  \"\"\"\n",
    "  response = get_completion(prompt)\n",
    "  print (response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例六：把口语转换为正式表达**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to bring to your attention a standing lamp that I believe may be of interest to you. Please find attached the specifications for your review.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Joe\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter:\n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例七：把JSON转换为HTML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <caption>Resturant Employees</caption>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Name</th>\n",
      "      <th>Email</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>Shyam</td>\n",
      "      <td>shyamjaiswal@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Bob</td>\n",
      "      <td>bob32@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Jai</td>\n",
      "      <td>jai87@gmail.com</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "data_json = { \"resturant employees\": [\n",
    "  {\"name\": \"Shyam\", \"email\": \"shyamjaiswal@gmail.com\"},\n",
    "  {\"name\": \"Bob\", \"email\": \"bob32@gmail.com\"},\n",
    "  {\"name\": \"Jai\", \"email\": \"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following python dictionary from JSON to HTML \\\n",
    "table with column headers and title: {data_json}\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <caption>Resturant Employees</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Shyam</td>\n",
       "      <td>shyamjaiswal@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bob</td>\n",
       "      <td>bob32@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jai</td>\n",
       "      <td>jai87@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "print (display(HTML(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例八：检查语法错误，并修改为正确的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "  \"The girl with the black and white puppies have a ball.\", # The girl has a ball\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it's oil changed?\", # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they're suitcases.\", # Homonyms\n",
    "  \"Your going to need your're notebook.\", # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have your heard of the butterfly affect?\",\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\" # spelling\n",
    "]\n",
    "\n",
    "for t in text:\n",
    "  prompt = f\"Proofread and correct: ```{t}```\"\n",
    "  response = get_completion(prompt)\n",
    "  print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例九：检查语法错误，并修改为正确的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in text:\n",
    "  prompt = f\"\"\"\n",
    "  Proofread and correct the following text\n",
    "  and rewrite the corrected version. If you don't find\n",
    "  any errors, just say \"No errors found\":\n",
    "  ```{t}```\n",
    "  \"\"\"\n",
    "  response = get_completion(prompt)\n",
    "  print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例十：检查语法错误，并修改为正确的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I got this for my daughter's birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I think there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\"\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Got this for my daughter for her birthday cuz she keeps taking \\\n",
    "mine from my froom. Yes, adults also like pandas too. She takes \\\n",
    "it everywhere with her, and it's super soft and cute. One of the \\\n",
    "ears is a bit lower than the other, and I don't think that was \\\n",
    "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
    "though. I think there might be other options that are bigger for \\\n",
    "the same price. It arrived a day earlier that expected, so I got \\\n",
    "to play with it myself before I gave it to my daughter.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Proofread and correct this review: ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:red;font-weight:700;text-decoration:line-through;\">Got </span><span style=\"color:red;font-weight:700;\">\"I got </span>this for my <span style=\"color:red;font-weight:700;text-decoration:line-through;\">daughter for her </span><span style=\"color:red;font-weight:700;\">daughter's </span>birthday <span style=\"color:red;font-weight:700;text-decoration:line-through;\">cuz </span><span style=\"color:red;font-weight:700;\">because </span>she keeps taking mine from my <span style=\"color:red;font-weight:700;text-decoration:line-through;\">froom. </span><span style=\"color:red;font-weight:700;\">room. </span>Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. <span style=\"color:red;font-weight:700;text-decoration:line-through;\">One </span><span style=\"color:red;font-weight:700;\">However, one </span>of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. <span style=\"color:red;font-weight:700;text-decoration:line-through;\">It's </span><span style=\"color:red;font-weight:700;\">Additionally, it's </span>a bit small for what I paid for <span style=\"color:red;font-weight:700;text-decoration:line-through;\">it though. </span><span style=\"color:red;font-weight:700;\">it. </span>I think there might be other options that are bigger for the same price. <span style=\"color:red;font-weight:700;text-decoration:line-through;\">It </span><span style=\"color:red;font-weight:700;\">On the positive side, it </span>arrived a day earlier <span style=\"color:red;font-weight:700;text-decoration:line-through;\">that </span><span style=\"color:red;font-weight:700;\">than </span>expected, so I got to play with it myself before I gave it to my <span style=\"color:red;font-weight:700;text-decoration:line-through;\">daughter.</span><span style=\"color:red;font-weight:700;\">daughter.\"</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "from IPython.core.display import Markdown\n",
    "diff = Redlines(text, response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**示例十一：检查语法错误，并修改为正确的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Review of a Panda Plush Toy\n",
      "\n",
      "I purchased this panda plush toy as a birthday gift for my daughter, who has a penchant for taking my belongings from my room. As an adult, I also have a soft spot for pandas, and I must say that this toy did not disappoint. \n",
      "\n",
      "My daughter takes it everywhere with her, and I can attest to its softness and cuteness. However, I did notice that one of the ears is slightly lower than the other, which I don't believe was intended to be asymmetrical. \n",
      "\n",
      "While I am pleased with the quality of the toy, I do feel that it is a bit small for the price I paid. I suspect that there may be other options available that are larger for the same cost. \n",
      "\n",
      "Despite this, I was pleasantly surprised to receive the toy a day earlier than expected, which gave me the opportunity to play with it myself before giving it to my daughter. Overall, I would recommend this panda plush toy to anyone who loves these adorable creatures, but be aware of its size and slight asymmetry.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Proofread and correct this review. Make it more compelling.\n",
    "Ensure it follows APA style guide and targets an advanced reader.\n",
    "Output in markdown format.\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Review of a Panda Plush Toy\n",
       "\n",
       "I purchased this panda plush toy as a birthday gift for my daughter, who has a penchant for taking my belongings from my room. As an adult, I also have a soft spot for pandas, and I must say that this toy did not disappoint. \n",
       "\n",
       "My daughter takes it everywhere with her, and I can attest to its softness and cuteness. However, I did notice that one of the ears is slightly lower than the other, which I don't believe was intended to be asymmetrical. \n",
       "\n",
       "While I am pleased with the quality of the toy, I do feel that it is a bit small for the price I paid. I suspect that there may be other options available that are larger for the same cost. \n",
       "\n",
       "Despite this, I was pleasantly surprised to receive the toy a day earlier than expected, which gave me the opportunity to play with it myself before giving it to my daughter. Overall, I would recommend this panda plush toy to anyone who loves these adorable creatures, but be aware of its size and slight asymmetry."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding\n",
    "\n",
    "Expand a shorter text to a longer text (email, essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear valued customer,\n",
      "\n",
      "Thank you for taking the time to leave a review about your recent purchase. We are sorry to hear that you experienced a price increase and that the quality of the product did not meet your expectations. We apologize for any inconvenience this may have caused.\n",
      "\n",
      "If you have any further concerns or questions, please do not hesitate to reach out to our customer service team. They will be more than happy to assist you in any way they can.\n",
      "\n",
      "Thank you again for your feedback. We appreciate your business and hope to have the opportunity to serve you better in the future.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "sentiment = \"negative\"\n",
    "\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn't look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "play to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ics, rice, etc. in the \\\n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruite and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\\n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\\n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service.\n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, temperature=0)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature\n",
    "\n",
    "temperature 是一个随机数，\n",
    "数字越小，表示结果越确定，\n",
    "数字越大，表示结果越随机。\n",
    "\n",
    "#### example\n",
    "\n",
    "my favorite food is xxx.\n",
    "\n",
    "- pizza: 53%\n",
    "- sushi: 30%\n",
    "- tacos: 5%\n",
    "\n",
    "temperature = 0 时，输出可能是：\n",
    "\n",
    "- my favorite food is pizza\n",
    "- my favorite food is pizza\n",
    "- my favorite food is pizza\n",
    "\n",
    "temperature = 0.3 时，输出可能是：\n",
    "\n",
    "- my favorite food is pizza\n",
    "- my favorite food is sushi\n",
    "- my favorite food is pizza\n",
    "\n",
    "temperature = 0.7 时，输出可能是：\n",
    "\n",
    "- my favorite food is tacos\n",
    "- my favorite food is sushi\n",
    "- my favorite food is pizza\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- for tasks that require reliability, predictability，set temperature = 0\n",
    "- for tasks that require variety, use temperature higher\n",
    "- 当 temperature = 0 时，每次都是相同的输出。\n",
    "- 当 temperature = 0.7 时，每次都会得到不同的输出。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get to yonder fairest hen, forsooth!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},\n",
    "  {'role':'user', 'content':'tell me a joke'},\n",
    "  {'role':'assistant', 'content':'Why did the chicken cross the road'},\n",
    "  {'role':'user', 'content':'I dont know'}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1.)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Isa! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {'role':'system', 'content':'You are friendly chatbot.'},\n",
    "  {'role':'user', 'content':'Hi, my name is Isa'},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1.)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but as a chatbot, I don't have access to your personal information, so I don't know your name. However, I'm happy to chat with you and answer any questions you may have.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {'role':'system', 'content':'You are friendly chatbot.'},\n",
    "  {'role':'user', 'content':'Yes, you can remind me, What is my name?'},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Your name is Isa.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {'role':'system', 'content':'You are friendly chatbot.'},\n",
    "  {'role':'user', 'content':'Hi, my name is Isa'},\n",
    "  {'role':'assistant', 'content':\"Hi Isa! It's nice to meet you \\\n",
    "      Is there anything I can help you with today?\"},\n",
    "  {'role':'user', 'content':'Yes, you can remind me, What is my name?'},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print (response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
